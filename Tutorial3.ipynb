{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9hC7S-ZOEN_"
   },
   "source": [
    "# Tutorial 3: Data Cleaning\n",
    "\n",
    "We have learned many useful Pandas functions in the previous tutorials. The learning goalas of this tutorial are as follows:\n",
    "\n",
    "- Identiy and Address Data Quality Issues: Detect missing values, duplicate entries and other inconsistencies in real-world datasets\n",
    "- Apply Data Cleaning Techniques in Python to address various inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGrcvd_5OEOC"
   },
   "source": [
    "# Getting Started: Loading the IMDB Movie Dataset\n",
    "\n",
    "Let's load the IMDB Movie Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAeEo9CZOEOD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies_df = pd.read_csv(\"https://raw.githubusercontent.com/rnanda17/data_science_BE/refs/heads/main/IMDB-Movie-Data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tloUWhPgOEOE"
   },
   "outputs": [],
   "source": [
    "movies_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gGVRDz7OEOE"
   },
   "source": [
    "# Finding Missing Values\n",
    "\n",
    "In the previous tutorials, you might have noticed that some values in our dataset were NaN (Not a Number). This is a special value that Pandas uses to indicate that a value is missing.\n",
    "\n",
    "We can systematically check for missing values in a DataFrame using the `isna()` function. This function returns a DataFrame of the same size as the original, but with boolean values. A value is `True` if the original value was NaN, and `False` otherwise.\n",
    "\n",
    "Let's see how it works in practice. Please refer to the documentation (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html) of the `isna()` function and apply it on the `movies_df` dataframe. Can you intepret the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aA-sdqaVOEOF"
   },
   "outputs": [],
   "source": [
    "movies_df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftI96tsbOEOF"
   },
   "source": [
    "The function works on a row-level. You will see its difficult to interpret the results. \n",
    "\n",
    "\n",
    "    The output is large (1000 rows Ã— 11 columns).\n",
    "\n",
    "    To find out which columns have missing values, you'd have to manually scan the entire table.\n",
    "\n",
    "\n",
    "\n",
    "We can aggregate the results to check which columns have missing values.\n",
    "\n",
    "How do we aggregate the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4TPeThJOEOF"
   },
   "source": [
    "### `any()`\n",
    "\n",
    "`any()` returns True for a column if any value in that column is missing. So now use the `any()` function with the `isna()` function to find out which columns of `movies_df` have missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLNeZ8FUOEOG"
   },
   "outputs": [],
   "source": [
    "#write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8zRABn0OEOG"
   },
   "source": [
    "Which columns have missing values? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0C7Twq8OEOH"
   },
   "source": [
    "### `sum()`\n",
    "\n",
    "The `sum()` function returns the sum of all the values. For boolean values, `True` is treated as `1` and `False` as `0`. So we can use `sum()` to count the number of `True` values. So how many missing values are there in each column? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtavDT0QOEOH"
   },
   "outputs": [],
   "source": [
    "#write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zImbs3pUOEOH"
   },
   "source": [
    "# Handling Missing Values\n",
    "\n",
    "We have seen that there are missing values in our dataset. But how do we deal with them?\n",
    "\n",
    "It is important to think about what a *missing value* means in the context of our dataset. For instance, if a Metascore is missing, it could mean that the movie was not rated by the Metacritic website.  If a Revenue value is missing, it could mean that the movie was not released yet or simply that the information is not available.\n",
    "\n",
    "With that in mind, we have two main options to handle missing values: removing or filling them. \n",
    "\n",
    "The best one depends on the situation and on the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NG5FEUk9OEOI"
   },
   "source": [
    "### Option 1: Remove the rows with missing values\n",
    "\n",
    "We can assume that if a value is missing, the entire row is not useful for our analysis. For example, if we are calculating the average Metascore per genre and a movie is missing its Metascore, it makes sense to exclude that movie from the calculation.\n",
    "\n",
    "We can remove the rows with missing values using the `dropna()` function.\n",
    "\n",
    "`dropna()` has a `how` parameter that can be set to `any` or `all`. The default value is `any`, which means that a row will be removed if any of its values are missing. If we set it to `all`, a row will be removed only if all of its values are missing.\n",
    "\n",
    "Let's try it out and remove all the rows with any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C18x7o8ROEOI"
   },
   "outputs": [],
   "source": [
    "movies_df.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y92h6YNCOEOI"
   },
   "source": [
    "We can also remove all rows with missing values in specific columns. For that, we can use the `subset` parameter and pass a list of column names.\n",
    "\n",
    "Let's remove all rows with missing values in the `Revenue (Millions)` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqHZloVfOEOI"
   },
   "outputs": [],
   "source": [
    "movies_df.dropna(subset=[\"Revenue (Millions)\"], how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKNE4wgpOEOJ"
   },
   "source": [
    "Remember that unless we set `inplace=True`, we are not modifying the original DataFrame. So we either need to assign the result to a new variable or set `inplace=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WvTLkguOEOJ"
   },
   "source": [
    "### Option 2: Fill the missing values\n",
    "\n",
    "Another option is to fill the missing values with some other value. This is useful if we want to keep all rows.\n",
    "\n",
    "There are different ways to fill the missing values. We can fill them with a constant value, or we can fill them with the mean, median or mode of the column.\n",
    "\n",
    "Again, the best option depends on the situation and on the dataset.\n",
    "\n",
    "The `fillna()` function can be used to fill the missing values. It has a `value` parameter that can be set to a constant value, or to a function that will be applied to the column.\n",
    "\n",
    "We can apply it directly to a specific column.\n",
    "\n",
    "Let's fill the missing values in the `Metascore` column with the mean value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metascore = movies_df[\"Metascore\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tg-ubNtiOEOJ"
   },
   "outputs": [],
   "source": [
    "metascore_filled_mean = movies_df[\"Metascore\"].fillna(mean_metascore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcsfpirkOEOJ"
   },
   "source": [
    "#### Task: check the descriptive statistics of the `Metascore` column before and after filling the missing values. What happened?\n",
    "\n",
    "Hint: You can use the `describe()` function to get the descriptive statistics (https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)\n",
    "\n",
    "Check it again after filling the missing values with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKyZtQNVOEOK"
   },
   "source": [
    "# Handling Duplicate Values\n",
    "\n",
    "We can also check if there are duplicate values in our dataset. Duplicate values are rows that have the same values in all (or a subset of) columns.\n",
    "\n",
    "If different rows have the exact same values in all columns, it is safe to assume they are duplicates. But if different rows have the same values in some columns, it is not clear if they are duplicates or not. For instance, if two movies have the same title, they could still be different. However, in our dataset, this is very unlikely.\n",
    "\n",
    "To check for duplicate values, we can use the `duplicated()` function. This function returns a Series of boolean values, with one value for each row. A value is `True` if the row is a duplicate, and `False` otherwise. It works very similarly to `isna()`.\n",
    "\n",
    "Let's check if there are any duplicate values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoAl8ke9OEOK"
   },
   "outputs": [],
   "source": [
    "movies_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRER5NXPOEOK"
   },
   "source": [
    "There are no duplicate values in our dataset. But let's test it for one column just to see how it works.\n",
    "\n",
    "Let's check if there are any duplicate (Director, Year) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJOrp0OYOEOK"
   },
   "outputs": [],
   "source": [
    "movies_df.duplicated(subset=[\"Director\", \"Year\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcGikQ5mOEOK"
   },
   "source": [
    "That means 13 rows have the same Director and Year as another row. Of course they are not duplicates, because they are different movies, so we don't need to remove them.\n",
    "\n",
    "But in case we wanted to remove them, we could use the `drop_duplicates()` function.\n",
    "\n",
    "It works very similarly to `dropna()`. We can use the `subset` parameter to specify which columns to consider when checking for duplicates.\n",
    "\n",
    "If we had duplicates in our dataset, we could remove them like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EB81KHagOEOL"
   },
   "outputs": [],
   "source": [
    "movies_df.drop_duplicates(subset=[\"Director\", \"Year\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wmy7PxePOEOL"
   },
   "source": [
    "The `keep` parameter can be set to `first` or `last`. If we set it to `first`, the first row will be kept and the rest will be removed. If we set it to `last`, the last row will be kept and the rest will be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Inspection on a Crime Dataset\n",
    "\n",
    "The dataset consists of observations from the year 1987 for the crime rate in North Carolina. The State consists of counties. The dataset is available here: https://raw.githubusercontent.com/rnanda17/data_science_BE/refs/heads/main/crime_1987.csv . The data is aggregated by county. A\n",
    "\n",
    "The dataset has been taken from this paper (http://qed.econ.queensu.ca/jae/datasets/baltagi003/) by only selecting for the year 1987. \n",
    "\n",
    "A brief description of various variables in the dataset is presented below:\n",
    "\n",
    "county\n",
    "\n",
    "    county identifier\n",
    "year\n",
    "\n",
    "    year = 1987\n",
    "crmrte\n",
    "\n",
    "    crimes committed per person\n",
    "prbarr\n",
    "\n",
    "    'probability' of arrest\n",
    "prbconv\n",
    "\n",
    "    'probability' of conviction\n",
    "prbpris\n",
    "\n",
    "    'probability' of prison sentence\n",
    "avgsen\n",
    "\n",
    "    average sentence, days\n",
    "polpc\n",
    "\n",
    "    police per capita\n",
    "density\n",
    "\n",
    "    hundreds of people per square mile\n",
    "taxpc\n",
    "\n",
    "    tax revenue per capita\n",
    "west\n",
    "\n",
    "    'west' = 1, if region is west for the State \n",
    "    \n",
    "central\n",
    "\n",
    "    'central' = 1, if region is central for the State\n",
    "\n",
    "urban\n",
    "\n",
    "    'urban' = 1 if in SMSA (Standard Metropolitan Statistical Area)\n",
    "    \n",
    "pctmin80\n",
    "\n",
    "    percentage minority in 1980\n",
    "    \n",
    "wcon\n",
    "\n",
    "    weekly wage in construction\n",
    "wtuc\n",
    "\n",
    "    weekly wage in trns, util, commun\n",
    "wtrd\n",
    "\n",
    "    weekly wage in whole sales and retail trade\n",
    "wfir\n",
    "\n",
    "    weekly wage in finance, insurance and real estate\n",
    "wser\n",
    "\n",
    "    weekly wage in service industry\n",
    "wmfg\n",
    "\n",
    "    weekly wage in manufacturing\n",
    "wfed\n",
    "\n",
    "    weekly wage of federal employees\n",
    "wsta\n",
    "\n",
    "    weekly wage of state employees\n",
    "wloc\n",
    "\n",
    "    weekly wage of local governments employees\n",
    "mix\n",
    "\n",
    "    offense mix: face-to-face/other\n",
    "pctymle\n",
    "\n",
    "    percentage of young males\n",
    "\n",
    "\n",
    "\n",
    "## ðŸ§© Exercise: Inspecting and Cleaning the Crime Dataset\n",
    "\n",
    "### Task 1: Load the Dataset\n",
    "Load the dataset as `df_crime`\n",
    "\n",
    "### Task 2: Inspect Data Types\n",
    "Use the `.info()` function to check the data types of each column\n",
    "\n",
    "### Task 3: Examine Summary Statistics\n",
    "Use the `.describe()` function to get the descriptive statistics of the dataset. Check the \n",
    "- The range of values in each column (identify any unusual minimum or maximum values)\n",
    "- If any anomalies are found, how would you address them ?\n",
    "\n",
    "### Task 4: Check for missing and duplicate values. Take appropriate action"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "P9hC7S-ZOEN_",
    "dGrcvd_5OEOC",
    "I4TPeThJOEOF",
    "h0C7Twq8OEOH",
    "COKuJwxcOEOL",
    "MD5-9J9kOEOM",
    "kXCHv7AnOEON",
    "f80PpRrpOEON",
    "1F-ZuKL_OEON",
    "jNgsoigpOEOO",
    "Q42R4ylzOEOP",
    "Jiq8hAvAOEOP",
    "dIhKp73KOEOP",
    "ppIQMBMwOEOP",
    "fxw9QrltOEOP",
    "FycCqtolOEOQ",
    "IhAKJTyMOEOQ",
    "xl6423bVOEOQ",
    "8cJ-JxKMOEOQ",
    "yCTpa6GlOEOQ",
    "i1BKkdTrOEOQ",
    "lRKzHfiiOEOR"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
